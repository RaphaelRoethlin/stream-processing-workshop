{"paragraphs":[{"text":"%md\n# Working with Kafka from Python","user":"anonymous","dateUpdated":"2019-06-02T12:31:04+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Working with Kafka from Python</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1559478650119_-1802564546","id":"20190602-123050_1707175081","dateCreated":"2019-06-02T12:30:50+0000","dateStarted":"2019-06-02T12:31:04+0000","dateFinished":"2019-06-02T12:31:06+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9721"},{"text":"%md\n## Setup Python environment","user":"anonymous","dateUpdated":"2019-06-02T12:31:15+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Setup Python environment</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1559478668181_401079956","id":"20190602-123108_843421398","dateCreated":"2019-06-02T12:31:08+0000","dateStarted":"2019-06-02T12:31:15+0000","dateFinished":"2019-06-02T12:31:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9722"},{"title":"Install Confluent Python client for Kafka","text":"%sh\npip install confluent-kafka","user":"anonymous","dateUpdated":"2019-06-02T12:30:16+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"editorMode":"ace/mode/sh","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Collecting confluent-kafka\n  Downloading https://files.pythonhosted.org/packages/1d/8a/ff15f0473398befb6fa70ddb4536291093780be6fa9770e2316ab2db2603/confluent_kafka-1.0.0-cp37-cp37m-manylinux1_x86_64.whl (7.3MB)\nInstalling collected packages: confluent-kafka\nSuccessfully installed confluent-kafka-1.0.0\nYou are using pip version 19.0.3, however version 19.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\n"}]},"apps":[],"jobName":"paragraph_1559478379578_919649376","id":"20190602-122619_790002730","dateCreated":"2019-06-02T12:26:19+0000","dateStarted":"2019-06-02T12:26:39+0000","dateFinished":"2019-06-02T12:26:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9723"},{"title":"Install Confluent Python support for Avro","text":"%sh\npip install confluent-kafka[avro]","user":"anonymous","dateUpdated":"2019-06-02T12:30:40+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"editorMode":"ace/mode/sh","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Requirement already satisfied: confluent-kafka[avro] in /usr/local/lib/python3.7/site-packages (1.0.0)\nCollecting fastavro; extra == \"avro\" (from confluent-kafka[avro])\n  Downloading https://files.pythonhosted.org/packages/af/fa/1c7b265aa44cf6089ce56a2702377a4994632016688b2b9ccde38a884024/fastavro-0.21.24-cp37-cp37m-manylinux1_x86_64.whl (1.2MB)\nCollecting avro-python3; extra == \"avro\" (from confluent-kafka[avro])\n  Downloading https://files.pythonhosted.org/packages/d1/55/4c2e6fecf06cbaa68e0abaf12e1e965969872ed16da3674e6245cab0d5e2/avro-python3-1.9.0.tar.gz\nCollecting requests; extra == \"avro\" (from confluent-kafka[avro])\n  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\nCollecting chardet<3.1.0,>=3.0.2 (from requests; extra == \"avro\"->confluent-kafka[avro])\n  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\nCollecting certifi>=2017.4.17 (from requests; extra == \"avro\"->confluent-kafka[avro])\n  Downloading https://files.pythonhosted.org/packages/60/75/f692a584e85b7eaba0e03827b3d51f45f571c2e793dd731e598828d380aa/certifi-2019.3.9-py2.py3-none-any.whl (158kB)\nCollecting idna<2.9,>=2.5 (from requests; extra == \"avro\"->confluent-kafka[avro])\n  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\nCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests; extra == \"avro\"->confluent-kafka[avro])\n  Downloading https://files.pythonhosted.org/packages/e6/60/247f23a7121ae632d62811ba7f273d0e58972d75e58a94d329d51550a47d/urllib3-1.25.3-py2.py3-none-any.whl (150kB)\nInstalling collected packages: fastavro, avro-python3, chardet, certifi, idna, urllib3, requests\n  Running setup.py install for avro-python3: started\n    Running setup.py install for avro-python3: finished with status 'done'\nSuccessfully installed avro-python3-1.9.0 certifi-2019.3.9 chardet-3.0.4 fastavro-0.21.24 idna-2.8 requests-2.22.0 urllib3-1.25.3\nYou are using pip version 19.0.3, however version 19.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\n"}]},"apps":[],"jobName":"paragraph_1559478384609_868927182","id":"20190602-122624_810213937","dateCreated":"2019-06-02T12:26:24+0000","dateStarted":"2019-06-02T12:26:59+0000","dateFinished":"2019-06-02T12:27:02+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9724"},{"text":"%md\n## Producing Messages to Kafka","user":"anonymous","dateUpdated":"2019-06-02T12:32:03+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Producing Messages to Kafka</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1559478678454_-200103912","id":"20190602-123118_846799181","dateCreated":"2019-06-02T12:31:18+0000","dateStarted":"2019-06-02T12:32:03+0000","dateFinished":"2019-06-02T12:32:03+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9725"},{"title":"Produce Value Only","text":"from confluent_kafka import Producer\n\np = Producer({'bootstrap.servers': 'broker-1:9092,broker-2:9093'})\nmessages = [\"message1\",\"message2\",\"message3\"]\n\ndef delivery_report(err, msg):\n    \"\"\" Called once for each message produced to indicate delivery result.\n        Triggered by poll() or flush(). \"\"\"\n    if err is not None:\n        print('Message delivery failed: {}'.format(err))\n    else:\n        print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition()))\n\nfor data in messages:\n    # Trigger any available delivery report callbacks from previous produce() calls\n    p.poll(0)\n\n    # Asynchronously produce a message, the delivery report callback\n    # will be triggered from poll() above, or flush() below, when the message has\n    # been successfully delivered or failed permanently.\n    p.produce('test-topic', data.encode('utf-8'), callback=delivery_report)\n\n# Wait for any outstanding messages to be delivered and delivery report\n# callbacks to be triggered.\np.flush()\n","user":"anonymous","dateUpdated":"2019-06-02T12:29:17+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionSupport":true},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Message delivered to test-topic [3]\nMessage delivered to test-topic [3]\nMessage delivered to test-topic [5]\n0\n"}]},"apps":[],"jobName":"paragraph_1559478419370_-2138764088","id":"20190602-122659_1589576879","dateCreated":"2019-06-02T12:26:59+0000","dateStarted":"2019-06-02T12:27:37+0000","dateFinished":"2019-06-02T12:27:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9726"},{"title":"Producing Key and Value","text":"from confluent_kafka import Producer\n\np = Producer({'bootstrap.servers': 'broker-1:9092,broker-2:9093'})\nmessages = [\"message1\",\"message2\",\"message3\"]\n\ndef delivery_report(err, msg):\n    \"\"\" Called once for each message produced to indicate delivery result.\n        Triggered by poll() or flush(). \"\"\"\n    if err is not None:\n        print('Message delivery failed: {}'.format(err))\n    else:\n        print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition()))\n\nfor data in messages:\n    # Trigger any available delivery report callbacks from previous produce() calls\n    p.poll(0)\n\n    # Asynchronously produce a message, the delivery report callback\n    # will be triggered from poll() above, or flush() below, when the message has\n    # been successfully delivered or failed permanently.\n    p.produce('test-topic'\n             , key=\"1\"\n             , value = data.encode('utf-8')\n             , callback=delivery_report)\n             \n# Wait for any outstanding messages to be delivered and delivery report\n# callbacks to be triggered.\np.flush()","user":"anonymous","dateUpdated":"2019-06-02T13:13:25+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionSupport":true},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1559478474429_879421769","id":"20190602-122754_1181663635","dateCreated":"2019-06-02T12:27:54+0000","dateStarted":"2019-06-02T12:43:45+0000","dateFinished":"2019-06-02T12:43:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9727"},{"text":"%md\n## Consuming Messages from Kafka","user":"anonymous","dateUpdated":"2019-06-02T12:32:07+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Consuming Messages from Kafka</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1559478457315_-2045404482","id":"20190602-122737_154822010","dateCreated":"2019-06-02T12:27:37+0000","dateStarted":"2019-06-02T12:32:07+0000","dateFinished":"2019-06-02T12:32:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9728"},{"title":"Consuming from Kafka","text":"from confluent_kafka import Consumer, KafkaError\n\nc = Consumer({\n    'bootstrap.servers': 'broker-1:9092,broker-2:9093',\n    'group.id': 'test-consumer-group',\n    'default.topic.config': {\n        'auto.offset.reset': 'largest'\n    }\n})\n\nc.subscribe(['test-topic'])\n\ngo_on = True\nwhile go_on:\n    msg = c.poll(1.0)\n\n    if msg is None:\n        continue\n    if msg.error():\n        if msg.error().code() == KafkaError._PARTITION_EOF:\n            continue\n        else:\n            print(msg.error())\n            break\n\n    print('Received message: {}'.format(msg.value().decode('utf-8')))\n    if msg.value().decode('utf-8') == \"STOP\":\n        go_on = False\nc.close()\n","user":"anonymous","dateUpdated":"2019-06-02T13:13:43+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionSupport":true},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Received message: STOP\n"}]},"apps":[],"jobName":"paragraph_1559478727838_-1206156031","id":"20190602-123207_273399012","dateCreated":"2019-06-02T12:32:07+0000","dateStarted":"2019-06-02T13:13:09+0000","dateFinished":"2019-06-02T13:13:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9729"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1559496792057_591373501","id":"20190602-173312_1368795785","dateCreated":"2019-06-02T17:33:12+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10107","text":"%md\n## Avro Support","dateUpdated":"2019-06-02T17:33:26+0000","dateFinished":"2019-06-02T17:33:26+0000","dateStarted":"2019-06-02T17:33:26+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Avro Support</h2>\n</div>"}]}},{"text":"from confluent_kafka import avro\nfrom confluent_kafka.avro import AvroProducer\n\nvalue_schema_str = \"\"\"\n{\n   \"namespace\": \"my.test\",\n   \"name\": \"Person\",\n   \"type\": \"record\",\n   \"fields\" : [\n     {\n       \"name\" : \"id\",\n       \"type\" : \"string\"\n     },\n     {\n       \"name\" : \"firstName\",\n       \"type\" : \"string\"\n     },\n     {\n       \"name\" : \"lastName\",\n       \"type\" : \"string\"\n     }\n   ]\n}\n\"\"\"\n\nkey_schema_str = \"\"\"\n{\n   \"namespace\": \"my.test\",\n   \"name\": \"PersonKey\",\n   \"type\": \"record\",\n   \"fields\" : [\n     {\n       \"name\" : \"id\",\n       \"type\" : \"string\"\n     }\n   ]\n}\n\"\"\"\n\nvalue_schema = avro.loads(value_schema_str)\nkey_schema = avro.loads(key_schema_str)\nvalue = {\"id\":\"1001\", \"firstName\": \"Peter\", \"lastName\": \"Muster\"}\nkey = {\"id\": \"1001\"}\n\navroProducer = AvroProducer({\n    'bootstrap.servers': 'broker-1:9092,broker-2:9093',\n    'schema.registry.url': 'http://schema-registry:8081',\n    'compression.codec': 'snappy'\n    }, default_key_schema=key_schema, default_value_schema=value_schema)\n\navroProducer.produce(topic='test-avro-topic', value=value, key=key)\navroProducer.flush()","user":"anonymous","dateUpdated":"2019-06-02T17:33:10+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionSupport":true},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"0\n"}]},"apps":[],"jobName":"paragraph_1559479420053_749588315","id":"20190602-124340_2107453258","dateCreated":"2019-06-02T12:43:40+0000","dateStarted":"2019-06-02T17:18:18+0000","dateFinished":"2019-06-02T17:18:19+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9730","title":"Produce Avro Message"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1559481346773_48329471","id":"20190602-131546_1760842900","dateCreated":"2019-06-02T13:15:46+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:9731"}],"name":"Working with Kafka from Python","id":"2ECM25NUM","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"python:shared_process":[],"sh:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}